# -*- coding: utf-8 -*-
import scrapy
import re
from datetime import datetime


class SecurityTrailsSpider(scrapy.Spider):
    name = 'SecurityTrails'
    domain = None
    reStr = '\w+\.'
    subdomains = set()
    baseUrl = 'https://securitytrails.com/'


    def start_requests(self):
        if self.domain is None:
            self.logger.error("Use scrapy crawl google -a domain=<domain to search>")
        else:
            self.reStr = self.reStr + self.domain
            yield scrapy.Request(
                url = 'https://securitytrails.com/list/apex_domain/' + self.domain,
                callback=self.parse
           )

    def parse(self, response):
        self.subdomains = set(re.findall(self.reStr, response.text))
        for subdomain in self.subdomains:
            shortSub = subdomain.split('.')[0]
            yield {
                    'Domain' : self.domain,
                    'Subdomain' : subdomain,
                    'ShortSubdomain' : shortSub,
                    'SourceSite' : self.name,
                    'InsertDate' : datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 
            }
        # Desenvolver uma forma de pegar a proxima pagina
        next_page = self.getNextPageUrl(response) 
        if next_page:
            url = self.baseUrl + next_page 
            yield scrapy.Request(url=url, callback=self.parse)


    def getNextPageUrl(self, response):
        return None
